{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from openai import OpenAI\n",
    "import secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition 2: continuous features with anchor images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the API key\n",
    "client = OpenAI(\n",
    "  api_key=secret.api_key,\n",
    ")\n",
    "\n",
    "# Function to encode the image to base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def query_model(image_path, prompt_text, anchor_images_info):\n",
    "\n",
    "    # Append the main image\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt_text},\n",
    "        {\"role\": \"user\", \"content\":[\n",
    "            {\"type\": \"text\", \"text\": f\"This is an example of a {anchor_images_info[0][1]} rock.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\":{\"url\":f\"data:image/jpeg;base64,{encode_image(anchor_images_info[0][0])}\"}}\n",
    "        ]},\n",
    "        {\"role\": \"user\", \"content\":[\n",
    "            {\"type\": \"text\", \"text\": f\"This is an example of a {anchor_images_info[1][1]} rock.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\":{\"url\":f\"data:image/jpeg;base64,{encode_image(anchor_images_info[1][0])}\"}}\n",
    "        ]},\n",
    "        {\"role\": \"user\", \"content\":[\n",
    "            {\"type\": \"text\", \"text\": f\"This is an example of a {anchor_images_info[2][1]} rock.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\":{\"url\":f\"data:image/jpeg;base64,{encode_image(anchor_images_info[2][0])}\"}}\n",
    "        ]},\n",
    "        {\"role\": \"user\", \"content\":[\n",
    "            {\"type\": \"text\", \"text\": \"This is the rock you will label.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\":{\"url\":f\"data:image/jpeg;base64,{encode_image(image_path)}\"}}\n",
    "        ]}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=5,\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def process_images(prompt_text, anchor_images_info, csv_file_path, image_directory, limit=0):\n",
    "    os.makedirs(os.path.dirname(csv_file_path), exist_ok=True)\n",
    "    try:\n",
    "        df_responses = pd.read_csv(csv_file_path)\n",
    "    except FileNotFoundError:\n",
    "        df_responses = pd.DataFrame(columns=['Image', 'Response'])\n",
    "\n",
    "    image_paths = [os.path.join(subdir, file) for subdir, dirs, files in os.walk(image_directory) for file in files if file.endswith(\".jpg\")]\n",
    "    image_paths.sort()\n",
    "\n",
    "    if limit > 1:\n",
    "        image_paths = image_paths[:limit]\n",
    "\n",
    "    for image_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "        row_label = os.path.basename(image_path)\n",
    "\n",
    "        if row_label not in df_responses['Image'].values:\n",
    "            #print(image_path)\n",
    "            response = query_model(image_path, prompt_text, anchor_images_info)\n",
    "            try:\n",
    "                parsed_response = response\n",
    "            except KeyError:\n",
    "                print(response)\n",
    "                break\n",
    "\n",
    "            row_data = {'Image': row_label, 'Response': parsed_response}\n",
    "            temp_df = pd.DataFrame([row_data])\n",
    "            df_responses = pd.concat([df_responses, temp_df], ignore_index=True)\n",
    "\n",
    "            # Save progress after each image is processed\n",
    "            df_responses.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    print(f\"Processing complete. Responses saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images_info = [\n",
    "    (\"Anchors_RGB/Low Lightness.jpg\", \"dark\"),\n",
    "    (\"Anchors_RGB/Medium Lightness.jpg\", \"medium\"),\n",
    "    (\"Anchors_RGB/High Lightness.jpg\", \"light\")\n",
    "]\n",
    "\n",
    "prompt_text = (\n",
    "'In this trial, you will rate a rock on its darkness/lightness of color. A dark rock should receive a rating of 1.00 or 2.00. A light rock should receive a rating of 8.00 or 9.00. A rock that is medium in darkness/lightness should receive a medium rating. An example of a very dark rock, a rock that is medium in darkness/lightness, and a very light rock is shown. In some cases, parts of the rock may be light and other parts may be dark. In those cases, do your best to rate the \"average\" lightness of the entire rock. Please try to use the full scale from 1.00 (darkest) through 9.00 (lightest) in making your rating. Please respond ONLY with a continuous numeric decimal value, allowing for any decimal places within the range of 1.00 to 9.00. Precision is key, and values should NOT be constrained to 0.05 increments. Your response can include any decimal point to the hundredths place within the specified range.'\n",
    ")\n",
    "\n",
    "process_images(prompt_text=prompt_text, anchor_images_info=anchor_images_info, csv_file_path=\"gpt4o_data_with_anchors_RGB/model_lightness_with_anchors.csv\", image_directory='Images_RGB', limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grain size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images_info = [\n",
    "    (\"Anchors_RGB/Low Grain Size.jpg\", \"low grain size\"),\n",
    "    (\"Anchors_RGB/Medium Grain Size.jpg\", \"medium grain size\"),\n",
    "    (\"Anchors_RGB/High Grain Size.jpg\", \"high grain size\")\n",
    "]\n",
    "\n",
    "prompt_text = (\n",
    "'In this trial, you will rate a rock on its average grain size. Rocks with no visible grain should receive a rating of 1.00 or 2.00. Rocks with an extremely coarse and fragmented grain should receive a rating of 8.00 or 9.00. Rocks with a medium grain should receive medium ratings. An example of a rock with no visible grain, with a medium grain, and with a very coarse and fragmented grain is shown. In some cases, parts of the rock may have a fine grain and other parts may have a coarse grain. In those cases, do your best to rate the \"average\" grain size of the entire rock. Please try to use the full scale from 1.00 (no visible grain) through 9.00 (very coarse grain) in making your rating. Please respond ONLY with a continuous numeric decimal value, allowing for any decimal places within the range of 1.00 to 9.00. Precision is key, and values should NOT be constrained to 0.05 increments. Your response can include any decimal point to the hundredths place within the specified range.'\n",
    ")\n",
    "\n",
    "process_images(prompt_text=prompt_text, anchor_images_info=anchor_images_info, csv_file_path=\"gpt4o_data_with_anchors_RGB/model_grain_size_with_anchors.csv\", image_directory='Images_RGB', limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roughness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images_info = [\n",
    "    (\"Anchors_RGB/Low Roughness.jpg\", \"low roughness\"),\n",
    "    (\"Anchors_RGB/Medium Roughness.jpg\", \"medium roughness\"),\n",
    "    (\"Anchors_RGB/High Roughness.jpg\", \"high roughness\")\n",
    "]\n",
    "\n",
    "prompt_text = (\n",
    "'In this trial, you will rate a rock on how smooth versus rough it appears to be. Rocks that appear to be very smooth should receive a rating of 1.00 or 2.00. Rocks that appear to be very rough should receive a rating of 8.00 or 9.00. Rocks that are medium in their smoothness/roughness should receive medium ratings. An example of a rock that is very smooth, that is medium in smoothness/roughness, and that is very rough is shown. In some cases, parts of a rock may be smooth and other parts may be rough. In those cases, do your best to rate the \"average\" roughness of the entire rock. Please try to use the full scale from 1.0 (smoothest) through 9.0 (roughest) in making your rating. Please respond ONLY with a continuous numeric decimal value, allowing for any decimal places within the range of 1.00 to 9.00. Precision is key, and values should NOT be constrained to 0.05 increments. Your response can include any decimal point to the hundredths place within the specified range.'\n",
    ")\n",
    "\n",
    "process_images(prompt_text=prompt_text, anchor_images_info=anchor_images_info, csv_file_path=\"gpt4o_data_with_anchors_RGB/model_roughness_with_anchors.csv\", image_directory='Images_RGB', limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shininess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images_info = [\n",
    "    (\"Anchors_RGB/Low Shininess.jpg\", \"low shininess\"),\n",
    "    (\"Anchors_RGB/Medium Shininess.jpg\", \"medium shininess\"),\n",
    "    (\"Anchors_RGB/High Shininess.jpg\", \"high shininess\")\n",
    "]\n",
    "\n",
    "prompt_text = (\n",
    "'An object is \"shiny\" if it reflects light and is glossy. Note that dark-colored objects can still be shiny. In this trial, you will rate a rock on how dull versus shiny it appears to be. Rocks that appear to be very dull should receive a rating of 1.00 or 2.00. Rocks that appear to be very shiny and glossy should receive a rating of 8.00 or 9.00. Rocks that are medium in their dullness/shininess should receive medium ratings. An example of a rock that is very dull, that is medium in dullness/shininess, and that is very shiny is shown. In some cases, parts of a rock may be dull and other parts may be shiny. In those cases, do your best to rate the \"average\" shininess of the entire rock. Please try to use the full scale from 1.00 (dullest) through 9.00 (shiniest) in making your rating. Please respond ONLY with a continuous numeric decimal value, allowing for any decimal places within the range of 1.00 to 9.00. Precision is key, and values should NOT be constrained to 0.05 increments. Your response can include any decimal point to the hundredths place within the specified range.'\n",
    ")\n",
    "\n",
    "process_images(prompt_text=prompt_text, anchor_images_info=anchor_images_info, csv_file_path=\"gpt4o_data_with_anchors_RGB/model_shininess_with_anchors.csv\", image_directory='Images_RGB', limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images_info = [\n",
    "    (\"Anchors_RGB/Low Regularity.jpg\", \"low organization\"),\n",
    "    (\"Anchors_RGB/Medium Regularity.jpg\", \"medium organization\"),\n",
    "    (\"Anchors_RGB/High Regularity.jpg\", \"high organization\")\n",
    "]\n",
    "\n",
    "prompt_text = (\n",
    "'Some rocks have components that are very regular and organized, such as systematic layers, bands, or grains. Other rocks seem very disorganized, such as those with fragments that are glued together in haphazard fashion. In this trial, you will rate a rock on how disorganized versus organized it appears to be. Rocks that are very disorganized should receive a rating of 1.00 or 2.00. Rocks that are very organized should receive a rating of 8.00 or 9.00. Rocks that are medium in their organization, or that have no visible texture to rate, should receive medium ratings. An example of a rock that is very disorganized, that is medium in organization, and that is highly organized is shown. Please try to use the full scale from 1.00 (most disorganized) through 9.00 (most organized) in making your rating. Please respond ONLY with a continuous numeric decimal value, allowing for any decimal places within the range of 1.00 to 9.00. Precision is key, and values should NOT be constrained to 0.05 increments. Your response can include any decimal point to the hundredths place within the specified range.'\n",
    ")\n",
    "\n",
    "process_images(prompt_text=prompt_text, anchor_images_info=anchor_images_info, csv_file_path=\"gpt4o_data_with_anchors_RGB/model_organization_with_anchors.csv\", image_directory='Images_RGB', limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chromaticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images_info = [\n",
    "    (\"Anchors_RGB/Warm Color.jpg\", \"warm color\"),\n",
    "    (\"Anchors_RGB/Cool Color2.jpg\", 'cool color'),\n",
    "    (\"Anchors_RGB/No Color2.jpg\", \"no color\")\n",
    "]\n",
    "\n",
    "prompt_text = (\n",
    "'In this trial, you will rate a rock in terms of whether it has no color, cool color, or warm color. Rocks with no color (absolute black, gray or white) should receive a rating of 1.00 or 2.00. Rocks with cool colors (blue, blue/green, and green) should receive medium ratings (4.00, 5.00, or 6.00). Rocks with very warm colors (yellow, orange, red) should receive ratings of 8.00 or 9.00. An example of a rock with no color, cool color, and warm color variation is shown. Please try to use the full scale from 1.00 (no color) through 9.00 (warmest color) in making your rating. Please try to use the full scale from 1.00 to 9.00 in making your rating. Please respond ONLY with a continuous numeric decimal value, allowing for any decimal places within the range of 1.00 to 9.00. Precision is key, and values should NOT be constrained to 0.05 increments. Your response can include any decimal point to the hundredths place within the specified range.'\n",
    ")\n",
    "\n",
    "process_images(prompt_text=prompt_text, anchor_images_info=anchor_images_info, csv_file_path=\"gpt4o_data_with_anchors_RGB/model_chromaticity_with_anchors.csv\", image_directory='Images_RGB', limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### red/green hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images_info = [\n",
    "    (\"Anchors_RGB/green.jpg\", \"green\"),\n",
    "    (\"Anchors_RGB/neutral_redgreen.jpg\", \"neutral\"),\n",
    "    (\"Anchors_RGB/red.jpg\", \"red\")\n",
    "]\n",
    "\n",
    "\n",
    "prompt_text = (\n",
    "'In this experiment, you will be presented with a picture of a rock. We would like you to rate the rock picture on a red-green contrast. Rocks that are most strongly red should receive ratings of 1.00 or 2.00. Rocks that are most strongly green should receive ratings of 8.00 or 9.00. Neutral rocks (black or white) that are absent of color should receive ratings of 5.00. Examples of these different cases are shown. For the remaining rocks, just decide whether the main color tends to be closer to red versus green. For example, most would agree that orange is closer to red than to green, so you might give orange rocks ratings of 2.00, 3.00, or 4.00. Likewise, most would agree that blue is closer to green than to red, so you might give blue rocks ratings of 6.00, 7.00, or 8.00. Please try to use the full scale from 1.00 to 9.00 in making your rating. Please respond ONLY with a continuous numeric decimal value, allowing for any decimal places within the range of 1.00 to 9.00. Precision is key, and values should NOT be constrained to 0.05 increments. Your response can include any decimal point to the hundredths place within the specified range.'\n",
    ")\n",
    "\n",
    "process_images(prompt_text=prompt_text, anchor_images_info=anchor_images_info, csv_file_path=\"gpt4o_data_with_anchors_RGB/model_red_green_with_anchors.csv\", image_directory='Images_RGB', limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### porphyritic texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images_info = [\n",
    "    (\"Anchors_RGB/high_porphyritic.jpg\", \"high porphyritic texture\"),\n",
    "    (\"Anchors_RGB/unclear_porphyritic.jpg\", 'unclear porphyritic texture'),\n",
    "    (\"Anchors_RGB/low_porphyritic.jpg\", \"low porphyritic texture\")\n",
    "]\n",
    "\n",
    "prompt_text = (\n",
    "\"In this experiment you will be presented with a picture of a rock. We are interested in your judgments about a very specific property of some of the rocks -- Certain kinds of rocks contain small fragments or pebbles that are glued into a separate background texture. THESE SMALL FRAGMENTS OR PEBBLES ARE SEPARATE FROM THE REST OF THE ROCK'S BACKGROUND ITSELF. We want you to rate each rock picture for this property. Rocks with no small fragments or pebbles glued into their separate background should receive a rating of 1.00 or 2.00. Rocks that definitely have small fragments or pebbles glued into their separate background should receive a rating of 8.00 or 9.00. Many rocks may be unclear cases; Some may have a coarse grain throughout, but don't really have separate small fragments glued into them. Other rocks may also be hard to judge because they have changes in shading that are not really separate glued fragments. These unclear cases should receive ratings of 4.00, 5.00 or 6.00. Examples of these different cases are shown. Please try to use the full scale from 1.00 through 9.00 in making your rating. Please try to use the full scale from 1.00 to 9.00 in making your rating. Please respond ONLY with a continuous numeric decimal value, allowing for any decimal places within the range of 1.00 to 9.00. Precision is key, and values should NOT be constrained to 0.05 increments. Your response can include any decimal point to the hundredths place within the specified range.\"\n",
    ")\n",
    "\n",
    "process_images(prompt_text=prompt_text, anchor_images_info=anchor_images_info, csv_file_path=\"gpt4o_data_with_anchors_RGB/model_porphyritic_with_anchors.csv\", image_directory='Images_RGB', limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pegmatitic structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images_info = [\n",
    "    (\"Anchors_RGB/strong_pegmatite.jpg\", \"high pegmatitic structure\"),\n",
    "    (\"Anchors_RGB/medium_pegmatite.jpg\", 'unclear pegmatitic structure'),\n",
    "    (\"Anchors_RGB/none_pegmatite.jpg\", \"low pegmatitic structure\")\n",
    "]\n",
    "\n",
    "prompt_text = (\n",
    "'In this experiment you will be presented with a picture of a rock. Certain rocks have very large-sized crystals that are embedded in a SEPARATE background. The crystals will often (but not always) appear as large shiny bands. Your job in this experiment is simply to judge the extent to which the rock shown in each picture has this property. Rocks that have nothing like this property should receive ratings of 1.00 or 2.00. Rocks that have a hint of this property should receive ratings of 4.00, 5.00, or 6.00. Rocks that strongly display this property should receive ratings of 8.00 or 9.00. Examples of these different cases are shown. Please try to use the full scale from 1.00 through 9.00 in making your rating. Note: Because this property is very rare, most of the time your response will be between 1.00 and 2.00. Please respond ONLY with a continuous numeric decimal value, allowing for any decimal places within the range of 1.00 to 9.00. Precision is key, and values should NOT be constrained to 0.05 increments. Your response can include any decimal point to the hundredths place within the specified range.'\n",
    ")\n",
    "\n",
    "process_images(prompt_text=prompt_text, anchor_images_info=anchor_images_info, csv_file_path=\"gpt4o_data_with_anchors_RGB/model_pegmatitic_with_anchors.csv\", image_directory='Images_RGB', limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conchoidal fracture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images_info = [\n",
    "    (\"Anchors_RGB/high_conchoidal.jpg\", \"high conchoidal fracture\"),\n",
    "    (\"Anchors_RGB/unclear_conchoidal.jpg\", 'unclear conchoidal fracture'),\n",
    "    (\"Anchors_RGB/low_conchoidal.jpg\", \"low conchoidal fracture\")\n",
    "]\n",
    "\n",
    "prompt_text = (\n",
    "'In this experiment, you will be presented with a picture of a rock. We are interested in your judgments about a very specific property of some rocks. The property is called CONCHOIDAL FRACTURES. Conchoidal fractures are formed when pieces of a brittle rock chip off and leave behind smooth, curved surfaces resembling the inside of a seashell. Conchoidal fractures are typically found in glassy or fine-grained rocks. In this trial of the experiment, you will be shown a rock picture. We want you to rate the rock picture for the extent to which it has conchoidal fractures. Rocks with flat or jagged surfaces, or rocks with no fractures should receive a rating of 1.00 or 2.00. Rocks with smooth, curved indents or fractures resembling the inside of a seashell should receive a rating of 8.00 or 9.00. Many rocks may be unclear cases: Some rocks may have fractures where pieces of the rock were chipped off, but they may not be as smooth or curved as true conchoidal fractures. Other rocks may also be hard to judge because they have changes in shading or color. These unclear cases should receive ratings of 4.00, 5.00, or 6.00. Ratings of 8.00 or 9.00 should be given only for rocks for which you are absolutely sure they have conchoidal fractures. Examples of these different cases are shown. Most rocks do not have conchoidal fractures and should receive low ratings. Please try to use the full scale from 1.00 through 9.00 in making your rating. Please respond ONLY with a continuous numeric decimal value, allowing for any decimal places within the range of 1.00 to 9.00. Precision is key, and values should NOT be constrained to 0.05 increments. Your response can include any decimal point to the hundredths place within the specified range.'\n",
    ")\n",
    "\n",
    "process_images(prompt_text=prompt_text, anchor_images_info=anchor_images_info, csv_file_path=\"gpt4o_data_with_anchors_RGB/model_conchoidal_with_anchors.csv\", image_directory='Images_RGB', limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global rocks index for image filename creation\n",
    "rocks_index = {\n",
    "    1: 'I_Andesite', 2: 'I_Basalt', 3: 'I_Diorite', 4: 'I_Gabbro', 5: 'I_Granite',\n",
    "    6: 'I_Obsidian', 7: 'I_Pegmatite', 8: 'I_Peridotite', 9: 'I_Pumice', 10: 'I_Rhyolite',\n",
    "    11: 'M_Amphibolite', 12: 'M_Anthracite', 13: 'M_Gneiss', 14: 'M_Hornfels', 15: 'M_Marble',\n",
    "    16: 'M_Migmatite', 17: 'M_Phyllite', 18: 'M_Quartzite', 19: 'M_Schist', 20: 'M_Slate',\n",
    "    21: 'S_Bituminous Coal', 22: 'S_Breccia', 23: 'S_Chert', 24: 'S_Conglomerate', 25: 'S_Dolomite',\n",
    "    26: 'S_Micrite', 27: 'S_Rock Gypsum', 28: 'S_Rock Salt', 29: 'S_Sandstone', 30: 'S_Shale'\n",
    "}\n",
    "\n",
    "# Function to format the image filename\n",
    "def create_image_filename(row):\n",
    "    rock_type = rocks_index.get(int(row['subtype']), 'Unknown')\n",
    "    token_str = str(int(row['token within subtype'])).zfill(2)\n",
    "    return f\"{rock_type}_{token_str}.jpg\"\n",
    "\n",
    "def load_and_preprocess_human_data(filepath, columns, image_naming_func, usecols=None, delimiter=None, header=None):\n",
    "    # Automatically determine the file type and choose the loading method\n",
    "    if filepath.endswith('.xlsx') or filepath.endswith('.xls'):\n",
    "        human_data = pd.read_excel(filepath, usecols=usecols, header=None)\n",
    "    elif filepath.endswith('.csv') or filepath.endswith('.txt'):\n",
    "        # For TXT files, a common use case is to have whitespace as a delimiter\n",
    "        if filepath.endswith('.txt'):\n",
    "            delimiter = delimiter if delimiter is not None else '\\s+'\n",
    "        human_data = pd.read_csv(filepath, header=header, delimiter=delimiter)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please provide a .csv, .txt, or .xlsx file.\")\n",
    "    \n",
    "    human_data.columns = columns\n",
    "    human_data = human_data.dropna()\n",
    "    human_data['Image'] = human_data.apply(image_naming_func, axis=1)\n",
    "    return human_data\n",
    "\n",
    "def load_gpt_data(filepaths, expected_columns, directory):\n",
    "    # Initialize an empty DataFrame with 'Image' column\n",
    "    combined_data = pd.DataFrame(columns=['Image'])\n",
    "    combined_data.set_index('Image', inplace=True)\n",
    "    \n",
    "    for filepath, new_col_name in zip(filepaths, expected_columns[1:]):  # Skip 'Image', which is common\n",
    "        # Load the current file\n",
    "        temp_df = pd.read_csv(directory + filepath)\n",
    "        \n",
    "        # Rename 'Response' to the new column name\n",
    "        temp_df.rename(columns={'Response': new_col_name}, inplace=True)\n",
    "        temp_df.set_index('Image', inplace=True)\n",
    "        \n",
    "        # Merge with the combined DataFrame\n",
    "        if combined_data.empty:\n",
    "            combined_data = temp_df\n",
    "        else:\n",
    "            combined_data = combined_data.join(temp_df, how='outer')\n",
    "    \n",
    "    combined_data.reset_index(inplace=True)\n",
    "    return combined_data\n",
    "\n",
    "def intersect_and_save_data(human_data, gpt_data, human_save_path, gpt_save_path):\n",
    "    # Calculate intersection of columns\n",
    "    columns_intersection = set(human_data.columns).intersection(gpt_data.columns)\n",
    "    print(columns_intersection)\n",
    "    \n",
    "    # Filter data by shared images\n",
    "    gpt_data_filtered = gpt_data[gpt_data['Image'].isin(human_data['Image'])]\n",
    "    human_data_filtered = human_data[human_data['Image'].isin(gpt_data['Image'])]\n",
    "\n",
    "    # Create dataframes with intersected columns\n",
    "    human_data_intersection = human_data_filtered[list(columns_intersection)]\n",
    "    gpt_data_intersection = gpt_data_filtered[list(columns_intersection)]\n",
    "\n",
    "    human_data_intersection.to_csv(human_save_path, index=False)\n",
    "    gpt_data_intersection.to_csv(gpt_save_path, index=False)\n",
    "\n",
    "def plot_correlations(csv_path_1, csv_path_2):\n",
    "    # Read the CSV files into pandas DataFrames\n",
    "    df1 = pd.read_csv(csv_path_1)\n",
    "    df2 = pd.read_csv(csv_path_2)\n",
    "\n",
    "    # Identify the intersection of columns between the two DataFrames, excluding 'Image' if it exists\n",
    "    common_columns = set(df1.columns).intersection(df2.columns)\n",
    "    common_columns.discard('Image')  # Exclude 'Image' column if present\n",
    "    common_columns = sorted(list(common_columns))\n",
    "\n",
    "    # Filter both DataFrames to only those common columns\n",
    "    df1_filtered = df1[common_columns].astype(float)\n",
    "    df2_filtered = df2[common_columns].astype(float)\n",
    "\n",
    "    # Plotting setup for square plots\n",
    "    num_features = len(common_columns)\n",
    "    num_rows = num_cols = int(np.ceil(np.sqrt(num_features)))\n",
    "\n",
    "    # Create figure and axes - handle single plot case differently\n",
    "    if num_features == 1:\n",
    "        fig, ax = plt.subplots(figsize=(4, 4), subplot_kw={'aspect': 'equal'})\n",
    "        axes = np.array([ax])  # Wrap single axis in array for consistent handling\n",
    "    else:\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols*4, num_rows*4), subplot_kw={'aspect': 'equal'})\n",
    "        axes = axes.flatten()  # Flatten only if multiple axes\n",
    "\n",
    "    fig.tight_layout(pad=4.0)\n",
    "\n",
    "    # Hide unused subplots if any (only needed for multiple plots)\n",
    "    if num_features > 1:\n",
    "        for i in range(num_features, len(axes)):\n",
    "            axes[i].set_visible(False)\n",
    "\n",
    "    # Plot each feature's correlation with ticks set to 1-9 regardless of the data\n",
    "    for i, feature in enumerate(common_columns):\n",
    "        x = df1_filtered[feature].values\n",
    "        y = df2_filtered[feature].values\n",
    "\n",
    "        # Calculate Pearson correlation\n",
    "        correlation, _ = pearsonr(x, y)\n",
    "\n",
    "        # Scatter plot\n",
    "        axes[i].scatter(x, y, label=f'Corr: {correlation:.2f}')\n",
    "        axes[i].set_title(f'{feature}')\n",
    "        axes[i].set_xlabel('GPT')\n",
    "        axes[i].set_ylabel('Human')\n",
    "\n",
    "        # Setting ticks from 1 to 9\n",
    "        axes[i].set_xticks(range(1, 10))\n",
    "        axes[i].set_yticks(range(1, 10))\n",
    "\n",
    "        # Optionally, set axis limits to better frame the ticks if necessary\n",
    "        axes[i].set_xlim(0, 10)\n",
    "        axes[i].set_ylim(0, 10)\n",
    "\n",
    "        # Fit line\n",
    "        m, b = np.polyfit(x, y, 1)\n",
    "        axes[i].plot(x, m * x + b, color='red', linestyle='--')\n",
    "        axes[i].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## continuous dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column names for the human data\n",
    "human_data_columns = ['subtype', 'token within subtype', 'darkness/lightness', 'fine/coarse grain',\n",
    "                      'smooth/rough', 'dull/shiny', 'disorganized/organized', 'chromaticity', 'red/green']\n",
    "\n",
    "# Load the human data from an Excel file\n",
    "human_data = load_and_preprocess_human_data(\n",
    "    filepath=\"Data/rocknorm3607_dat_catnumbered.xlsx\",\n",
    "    columns=human_data_columns,\n",
    "    image_naming_func=create_image_filename,\n",
    "    usecols=[i for i in range(9)]  # Specify the columns to use from the Excel file\n",
    ")\n",
    "\n",
    "# Define the specific GPT columns to include\n",
    "gpt_columns = ['Image', 'darkness/lightness', 'fine/coarse grain', 'smooth/rough', \n",
    "               'dull/shiny', \n",
    "               'disorganized/organized', 'chromaticity', 'red/green'\n",
    "              ]\n",
    "\n",
    "# Specify the list of GPT data files\n",
    "gpt_files = [\n",
    "    'model_lightness_with_anchors.csv', 'model_grain_size_with_anchors.csv', 'model_roughness_with_anchors.csv',\n",
    "    'model_shininess_with_anchors.csv', 'model_organization_with_anchors.csv', 'model_chromaticity_with_anchors.csv',\n",
    "    'model_red_green_with_anchors.csv'\n",
    "]\n",
    "\n",
    "# Load and combine the GPT data from multiple CSV files\n",
    "save_directory = 'gpt4o_data_with_anchors_RGB/'\n",
    "gpt_data = load_gpt_data(gpt_files, gpt_columns, save_directory)\n",
    "\n",
    "# Intersect the human and GPT data based on the 'Image' column, then save the intersected data\n",
    "intersect_and_save_data(\n",
    "    human_data=human_data,\n",
    "    gpt_data=gpt_data,\n",
    "    human_save_path='human_continuous_combined.csv',\n",
    "    gpt_save_path='gpt4o_data_with_anchors_RGB/model_continuous_with_anchors_combined.csv'\n",
    ")\n",
    "\n",
    "# Plot the correlations between the saved datasets\n",
    "plot_correlations(\n",
    "    csv_path_1='gpt4o_data_with_anchors_RGB/model_continuous_with_anchors_combined.csv',\n",
    "    csv_path_2='human_continuous_combined.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## supplementary dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns for human data\n",
    "human_data_columns = ['rock number', 'subtype', 'token within subtype', 'porphyritic texture', \n",
    "                      'presence of holes', 'green hue', 'pegmatitic structure', 'conchoidal fracture']\n",
    "\n",
    "\n",
    "# Load human data\n",
    "human_data = load_and_preprocess_human_data(\n",
    "    filepath=\"Data/supp540.txt\",\n",
    "    columns=human_data_columns,\n",
    "    image_naming_func=create_image_filename\n",
    ")\n",
    "\n",
    "gpt_columns = ['Image', 'porphyritic texture', 'pegmatitic structure', 'conchoidal fracture']\n",
    "\n",
    "gpt_files = [\n",
    "    'model_porphyritic_with_anchors.csv',\n",
    "    'model_pegmatitic_with_anchors.csv',\n",
    "    'model_conchoidal_with_anchors.csv'\n",
    "]\n",
    "\n",
    "# Load and process GPT data\n",
    "save_directory = 'gpt4o_data_with_anchors_RGB/'\n",
    "gpt_data = load_gpt_data(gpt_files, gpt_columns, save_directory)\n",
    "\n",
    "# Intersect and save the processed data\n",
    "intersect_and_save_data(\n",
    "    human_data=human_data,\n",
    "    gpt_data=gpt_data,\n",
    "    human_save_path='human_supplementary_combined.csv',\n",
    "    gpt_save_path='gpt4o_data_with_anchors_RGB/model_supplementary_with_anchors_combined.csv'\n",
    ")\n",
    "\n",
    "# Plot correlations\n",
    "plot_correlations(\n",
    "    csv_path_1='gpt4o_data_with_anchors_RGB/model_supplementary_with_anchors_combined.csv',\n",
    "    csv_path_2='human_supplementary_combined.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def plot_correlations(csv_path_pairs):\n",
    "    # Set the font properties\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rcParams['font.size'] = 48  # You can also set the font size here\n",
    "\n",
    "    # Define the fixed dimensions for a 2x5 grid\n",
    "    num_rows = 2\n",
    "    num_cols = 5\n",
    "    horizontal_spacing = 0.4  # Adjust horizontal spacing here\n",
    "    vertical_spacing = 0.5    # Adjust vertical spacing here\n",
    "\n",
    "    # Create a large figure to hold all subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols*10, num_rows*9.5))\n",
    "    \n",
    "    # Adjust subplot layout\n",
    "    plt.subplots_adjust(wspace=horizontal_spacing, hspace=vertical_spacing)\n",
    "    \n",
    "    # Adjust for when there's a single subplot\n",
    "    if not isinstance(axes, np.ndarray):\n",
    "        axes = np.array([axes])\n",
    "        \n",
    "    axes_flat = axes.flatten()\n",
    "    plot_index = 0\n",
    "    \n",
    "    # Fixed ticks\n",
    "    ticks = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "    # Iterate over each pair of CSV files\n",
    "    for csv_path_1, csv_path_2 in csv_path_pairs:\n",
    "        df1 = pd.read_csv(csv_path_1)\n",
    "        df2 = pd.read_csv(csv_path_2)\n",
    "        \n",
    "        # Identify common columns, excluding 'Image'\n",
    "        common_columns = sorted(list(set(df1.columns).intersection(df2.columns) - {'Image'}))\n",
    "        \n",
    "        # Filter DataFrames to these columns\n",
    "        df1_filtered = df1[common_columns].astype(float)\n",
    "        df2_filtered = df2[common_columns].astype(float)\n",
    "        \n",
    "        # Plot each feature in its own subplot\n",
    "        for feature in common_columns:\n",
    "            if plot_index >= len(axes_flat):\n",
    "                break  # Stop if there are more features than subplot spaces\n",
    "\n",
    "            x = df1_filtered[feature].values\n",
    "            y = df2_filtered[feature].values\n",
    "            correlation, _ = pearsonr(x, y)\n",
    "            ax = axes_flat[plot_index]\n",
    "            ax.scatter(x, y)\n",
    "            ax.set_title(feature, pad=25)\n",
    "\n",
    "            # Set axis limits and ticks\n",
    "            ax.set_xlim(0.5, 9.5)\n",
    "            ax.set_ylim(0.5, 9.5)\n",
    "            ax.set_aspect('equal')\n",
    "            ax.set_xticks(ticks)\n",
    "            ax.set_yticks(ticks)\n",
    "\n",
    "            ax.tick_params(axis='both', which='major', direction='inout', length=10, width=2)\n",
    "\n",
    "\n",
    "            # Modify spines to remove the top and right box borders\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "            # Fit line\n",
    "            m, b = np.polyfit(x, y, 1)\n",
    "            ax.plot(x, m*x + b, 'r-')\n",
    "            ax.text(1.25, 8.5, f'r = {correlation:.2f}', fontsize=48, color='black')\n",
    "\n",
    "            # Conditional label setting for Y-axis\n",
    "            if plot_index % num_cols == 0:  # For plots on the left side in each row\n",
    "                ax.set_ylabel('Human', labelpad=20)\n",
    "            else:\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "            # Conditional label setting for X-axis\n",
    "            if plot_index >= num_cols * (num_rows - 1):  # For all plots in the last row\n",
    "                ax.set_xlabel('GPT', labelpad=20)\n",
    "            else:\n",
    "                ax.set_xlabel('')\n",
    "\n",
    "            plot_index += 1\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for k in range(plot_index, len(axes_flat)):\n",
    "        axes_flat[k].set_visible(False)\n",
    "\n",
    "    plt.savefig('correlation_plots_gpt4o_cond2.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "\n",
    "    # Define the complete list of CSV file pairs\n",
    "csv_path_pairs = [\n",
    "    ('gpt4o_data_with_anchors_RGB/model_continuous_with_anchors_combined.csv', 'human_continuous_combined.csv'),\n",
    "    ('gpt4o_data_with_anchors_RGB/model_supplementary_with_anchors_combined.csv', 'human_supplementary_combined.csv')\n",
    "]\n",
    "\n",
    "# Plot all correlations in a 2x5 grid\n",
    "plot_correlations(csv_path_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rocks-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
